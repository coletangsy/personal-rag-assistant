# ğŸ¤– Personal RAG Assistant

A sophisticated AI-powered personal assistant that combines Retrieval-Augmented Generation (RAG) with a multi-agent workflow to provide intelligent, context-aware responses based on personal knowledge bases including Obsidian vaults and PDF documents.


## ğŸ“¹ Demo
https://github.com/user-attachments/assets/dc462521-ccde-4a76-9b33-023ec03f2bb2


## ğŸ†• What's New

### Latest Updates (October 2025)

**ğŸš€ Enhanced Multi-Agent RAG System**
- **Early Safety Validation**: Questions are now evaluated for safety before processing, ensuring appropriate content filtering
- **Content Quality Ranking**: Automatic evaluation of retrieved information quality with multi-attempt retrieval for better answers
- **Professional Response Formatting**: Final answers are now polished with clear structure, proper formatting, and accessibility improvements
- **Improved Error Handling**: More robust error recovery and user-friendly error messages

**ğŸŒ Web API & Containerization**
- **FastAPI Web Interface**: Full REST API with session management and health checks
- **Docker Support**: Complete containerization with optimized Dockerfile and docker-compose
- **AWS Lambda Ready**: Mangum integration for serverless deployment
- **Interactive Web Chat**: HTML chat interface for browser-based interaction

**ğŸ”§ Better Project Organization**
- **Modular Architecture**: Clean separation between CLI and API interfaces
- **Enhanced Configuration**: Flexible config.json with multiple fallback paths
- **Better Developer Experience**: Clear separation between application logic, agents, and data management

**What This Means for You:**
- More reliable and safe responses to your questions
- Higher quality answers with better information filtering
- Professional-looking responses with proper formatting
- Multiple deployment options (CLI, Web API, Docker)
- Easier to customize and extend the system
- More stable and maintainable application


**Getting Started with the Latest Version:**
```bash
uv run src/main.py
```


## âœ¨ Features

### ğŸ¯ Core Functionality
- **Multi-Agent Workflow**: Safety validation â†’ Assistant â†’ Retriever â†’ Ranker â†’ PR processing
- **RAG Integration**: Retrieval-Augmented Generation powered by Chroma vector database
- **Early Safety Validation**: Question safety evaluation before processing
- **Content Quality Ranking**: Automatic evaluation of retrieved content quality
- **Obsidian & PDF Integration**: Seamlessly indexes and retrieves information from Obsidian vaults and PDF documents
- **Interactive Interfaces**: Command-line interface and web API with real-time feedback

### ğŸ› ï¸ Technical Features
- **LangGraph Integration**: Multi-agent workflow orchestration
- **Google Gemini Models**: State-of-the-art LLM and embedding models
- **FastAPI Web Server**: Modern async web framework with automatic docs
- **Docker Containerization**: Ready-to-deploy containerized application
- **Modular Architecture**: Clean separation of concerns with dedicated modules
- **Error Handling**: Robust error recovery and graceful degradation
- **Progress Indicators**: Real-time status updates during processing
- **UV Package Management**: Fast and reliable dependency management


## ğŸš€ Quick Start

### Prerequisites
- Python 3.12+
- UV package manager
- Google Gemini API key

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/coletangsy/personal-rag-assistant.git
   cd personal-rag-assistant
   ```

2. **Install dependencies**
   ```bash
   uv sync
   ```

3. **Set up your environment**
   Create a `.env` file:
   ```env
   GOOGLE_API_KEY=<your_google_api_key_here>
   ```

4. **Configure your knowledge sources**
   Edit `config.json`:
   ```json
   {
    "llm": {
        "model": "gemini-2.5-flash",
        "temperature": 0
    },
    "vector_store": {
        "persist_directory": "./data/",
        "collection_name": "obsidian",
        "embedding_model": "models/gemini-embedding-001"
    },
    "pdf": {
        "path": ""
    },
    "obsidian": {
        "path": "/path/to/your/obsidian/vault"
    },
    "retriever": {
        "search_type": "similarity",
        "k": 3
    },
    "text_splitter": {
        "chunk_size": 1000,
        "chunk_overlap": 200
    }
   }
   ```

5. **Run the application**
- **Option 1: Command Line Interface**
    ```bash
    uv run  -m src/rag_app/main.py
    ```

- **Option 2: Web API Server**
    ```bash
    uv run  src/app_api_handler.py
    ```

    Then visit: http://localhost:8000/docs for API documentation

- **Option 3: Docker Container**
    ```bash
    # Build and run with Docker
    docker build -t personal-rag-assistant .
    docker run -p 8000:8000 -e GOOGLE_API_KEY=<your_key> personal-rag-assistant

    # Or use docker-compose
    docker-compose up
    ```


## ğŸ“ Project Structure

```
personal-rag-assistant/
â”œâ”€â”€ ğŸ“ src/                    # Main source code
â”‚   â”œâ”€â”€ rag_app/              # Core RAG application
â”‚   â”‚   â”œâ”€â”€ main.py           # CLI application entry point
â”‚   â”‚   â”œâ”€â”€ agents.py         # All agent functions (safety, assistant, ranker, PR)
â”‚   â”‚   â””â”€â”€ retriever_manager.py  # Vector database and document processing
â”‚   â”œâ”€â”€ app_api_handler.py    # FastAPI web server and API endpoints
â”‚   â””â”€â”€ data/                 # Data storage (vector database, documents) ignored
â”‚       â”œâ”€â”€ chroma.sqlite3    # Chroma vector database
â”‚       â”œâ”€â”€ vector_indices/   # Vector index files
â”‚       â””â”€â”€ harrypotter.pdf   # Sample PDF document
â”œâ”€â”€ chat_interface.html       # Web chat interface
â”œâ”€â”€ config.json               # Application configuration
â”œâ”€â”€ Dockerfile                # Container configuration
â”œâ”€â”€ docker-compose.yml        # Multi-container setup
â”œâ”€â”€ pyproject.toml            # Project dependencies (uv)
â”œâ”€â”€ uv.lock                   # Dependency lock file
â”œâ”€â”€ .env                      # Environment variables
â””â”€â”€ README.md                 # Project documentation
```


## ğŸ® Usage

### Interactive Session Example
```
âœ… Configuration loaded from config.json
ğŸš€ Initializing RAG System Components...

âœ… LLM initialized
âœ… Retriever Manager initialized
âœ… Retriever initialized
âœ… Retriever tool created

ğŸ§© Building Enhanced RAG Agent Graph with Early Safety...
âœ… Enhanced RAG Agent with Early Safety compiled successfully

============================================================
ğŸ’¬ RAG Conversation Started
Type 'exit', 'quit', or 'stop' to end the conversation
============================================================

â“ What is your question: What is machine learning?
ğŸ”„ Processing question: 'What is machine learning?'
ğŸ”’ Safety Agent: Evaluating question safety
ğŸ”’ Safety agent checking question: 'What is machine learning?'
...
ğŸ¤– Final Answer: Machine learning is a subset of artificial intelligence...
```

### Agent Workflow
1. **Safety Agent**: Validates question safety before processing
2. **Assistant Agent**: Generates search queries for information retrieval
3. **Retriever Agent**: Executes searches in the knowledge base
4. **Ranker Agent**: Evaluates quality of retrieved content
5. **PR Agent**: Processes final answer with proper formatting and context


## ğŸ”§ Configuration

### Environment Variables
| Variable | Description | Required |
|----------|-------------|----------|
| `GOOGLE_API_KEY` | API key for Google Gemini models | âœ… |

### Configuration Options
- **LLM Settings**: Model selection, temperature control
- **Vector Store**: Persistence directory, collection names, embedding models
- **Document Sources**: PDF and Obsidian vault paths
- **Retriever Settings**: Search type, result count (k)
- **Text Processing**: Chunk size and overlap for document splitting


## ğŸ”„ Agent Workflow Details

### Safety Validation
- Early question safety evaluation
- Prevents processing of harmful or inappropriate content
- Configurable safety criteria

### Content Retrieval
- Automatic vector database initialization
- Support for multiple document formats (PDF, Markdown)
- Configurable search parameters

### Quality Assessment
- Automatic ranking of retrieved content
- Multi-attempt retrieval for better results
- Maximum attempt limits to prevent infinite loops

### Response Generation
- Final answer polishing and formatting
- Context-aware response generation
- Professional tone and accessibility


## Future Enhancements
- [X] **GUI Interface**: Develop a web-based interface
- [ ] **Advanced Caching**: Implement response caching for frequently asked questions
- [ ] **Web Search Integration**: Add real-time web search capabilities
- [ ] **Advanced Analytics**: Performance monitoring and usage analytics
